# -*- coding: utf-8 -*-
"""colab.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1f5kPGrFPOa0OzHVpRea9i5tynZHcBm9w
"""

pip install tensorflow streamlit pyngrok pillow numpy opencv-python

!pip install kagglehub split-folders

import kagglehub

# Download latest version
path = kagglehub.dataset_download("emmarex/plantdisease")

print("Path to dataset files:", path)

!pip install kagglehub split-folders

!pip install streamlit pyngrok

import os

path = "/kaggle/input/plantdisease"

for root, dirs, files in os.walk(path):
    print(root)
    print("Folders:", dirs)
    print("Files:", files)

import splitfolders

input_folder = "/kaggle/input/plantdisease/PlantVillage"
output_folder = "/kaggle/working/PlantVillage_split"

splitfolders.ratio(
    input_folder,
    output=output_folder,
    seed=42,
    ratio=(0.8, 0.2)
)

print("Split created at:", output_folder)

train_dir = "/kaggle/working/PlantVillage_split/train"
val_dir   = "/kaggle/working/PlantVillage_split/val"

import tensorflow as tf
import splitfolders

train_base = "/kaggle/input/plantdisease/PlantVillage"
output_path = "/kaggle/working/PlantVillage_split"

# Create train/validation split
splitfolders.ratio(train_base, output=output_path, seed=42, ratio=(0.8,0.2))

train_dir = output_path + "/train"
val_dir   = output_path + "/val"

from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.models import Model
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout

img_size = 224
batch_size = 32

train_gen = ImageDataGenerator(rescale=1./255,
                               rotation_range=20,
                               zoom_range=0.2,
                               shear_range=0.2,
                               horizontal_flip=True)

val_gen = ImageDataGenerator(rescale=1./255)

train_data = train_gen.flow_from_directory(train_dir,
      target_size=(img_size, img_size),
      batch_size=batch_size,
      class_mode='categorical')

val_data = val_gen.flow_from_directory(val_dir,
      target_size=(img_size, img_size),
      batch_size=batch_size,
      class_mode='categorical')

base_model = MobileNetV2(include_top=False,
                         input_shape=(img_size, img_size, 3),
                         weights='imagenet')


base_model.trainable = False

x = GlobalAveragePooling2D()(base_model.output)
x = Dropout(0.3)(x)
output = Dense(train_data.num_classes, activation='softmax')(x)

model = Model(inputs=base_model.input, outputs=output)
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

history = model.fit(train_data, validation_data=val_data, epochs=5)

model.save("/kaggle/working/agrodetect_model.h5")

print("Model saved!")

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import tensorflow as tf
# import numpy as np
# from PIL import Image
# 
# # âœ… Load model (supports .h5 or .keras)
# model = tf.keras.models.load_model("plant_disease_model.keras")  # change to .h5 if needed
# 
# # ðŸŽ¯ App Title
# st.title("ðŸŒ¿ AgroDetect AI â€“ Plant Disease Classification Engine")
# st.write("Upload a plant leaf image to detect possible disease")
# 
# # âš ï¸ Replace these with your actual classes
# class_names = ['Apple Scab', 'Apple Black Rot', 'Corn Rust', 'Healthy']
# 
# # ---------------------------
# # ðŸ” IMAGE PREPROCESSING
# # ---------------------------
# def preprocess_image(image):
#     image = image.resize((224, 224))
#     image = np.array(image) / 255.0
#     image = np.expand_dims(image, axis=0)
#     return image
# 
# # ---------------------------
# # ðŸ“¤ FILE UPLOADER
# # ---------------------------
# uploaded_file = st.file_uploader("Upload leaf image", type=["jpg", "jpeg", "png"])
# 
# if uploaded_file:
#     image = Image.open(uploaded_file)
#     st.image(image, width=300, caption="Uploaded Leaf Image")
# 
#     img = preprocess_image(image)
#     prediction = model.predict(img)
# 
#      class_id = np.argmax(prediction)
#     confidence = np.max(prediction)
# 
#     st.subheader(f"ðŸŒ± Predicted: {class_names[class_id]}")
#     st.write(f"ðŸ¤– Confidence: {confidence * 100:.2f}%")
# 
#     # ðŸŒ¿ Remedies Dictionary
#     remedies = {
#         "Apple Scab": "Use fungicides like captan or mancozeb, remove infected leaves.",
#         "Apple Black Rot": "Prune infected branches, apply copper-based fungicide.",
#         "Corn Rust": "Use resistant hybrid varieties, apply triazole fungicide.",
#         "Healthy": "Plant is healthy! No treatment is required."
#     }
# 
#     st.info(remedies[class_names[class_id]])

!pip install streamlit pyngrok

from pyngrok import ngrok

# paste your token inside quotes
ngrok.set_auth_token("3A6r1bxbLwznltgvW8qBbBxeeSI_6GJARUTK9HxdrsYrofSYu")

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# 
# st.title("Hello from Streamlit inside Google Colab!")
# st.write("Your AgroDetect App will work here.")

!streamlit run app.py &>/dev/null&

from pyngrok import ngrok

# Streamlit runs on port 8501
public_url = ngrok.connect(8501)
public_url

model.save("agrodetect_model.keras")

from google.colab import files
files.download("agrodetect_model.keras")